{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read In and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify = pd.read_csv('https://raw.githubusercontent.com/cjsyndergaard/project_486/main/data/spotify_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that the same song has multiple track genres on different lines\n",
    "spotify[spotify['artists'] == 'Jim Croce'][['track_id', 'artists', 'track_name', 'track_genre']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only one genre per song\n",
    "spotify = spotify.drop_duplicates(subset=['track_id'], keep='first', ignore_index=True)\n",
    "x = spotify.iloc[:,5:20]\n",
    "genre = spotify['track_genre']\n",
    "genre.value_counts().plot.bar(figsize=(20, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, genre, random_state=307, test_size=.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_rf = RandomForestClassifier(n_estimators=500, random_state=7567)\n",
    "\n",
    "genre_rf.fit(xtrain, ytrain)\n",
    "yhat = genre_rf.predict(xtest)\n",
    "print(accuracy_score(yhat, ytest))\n",
    "c =  confusion_matrix(ytest, yhat)\n",
    "# Clearly, the correct genres are the most likely values, but it is very difficult.\n",
    "sns.heatmap(c, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Genre vs Natural Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super genres, chosen with research and domain knowledge\n",
    "entertainment = ['anime', 'children','disney', 'kids', 'opera', 'show-tunes']\n",
    "electronic = ['afrobeat', 'ambient', 'breakbeat', 'chicago-house', 'club', 'dance', 'dancehall',\n",
    "              'deep-house', 'detroit-techno', 'disco', 'dub', 'dubstep', 'edm', 'electro', 'electronic',\n",
    "              'funk', 'happy', 'house', 'idm',  'industrial', 'minimal-techno', 'progressive-house', \n",
    "              'techno', 'trance', 'drum-and-bass']\n",
    "rock = ['alt-rock', 'black-metal', 'death-metal', 'emo', 'garage', 'goth', 'grindcore', 'groove',\n",
    "        'grunge', 'hard-rock', 'hardcore', 'hardstyle', 'heavy-metal', 'j-rock', 'metal', 'metalcore',\n",
    "        'psych-rock', 'punk', 'punk-rock', 'rock', 'rock-n-roll']\n",
    "pop = ['cantopop', 'hip-hop', 'indie', 'indie-pop', 'j-dance', 'j-idol', 'j-pop', 'k-pop',\n",
    "       'mandopop', 'party', 'pop', 'pop-film', 'power-pop', 'synth-pop', 'trip-hop', 'alternative']\n",
    "folk = ['acoustic', 'blues', 'folk', 'honky-tonk', 'jazz', 'r-n-b', 'singer-songwriter', 'soul',\n",
    "        'bluegrass', 'country', 'guitar', 'rockabilly']\n",
    "latin = ['latin', 'latino', 'brazil', 'forro', 'mpb', 'pagode', 'reggae', 'reggaeton', 'salsa', 'samba',\n",
    "         'sertanejo', 'ska', 'spanish', 'tango']\n",
    "foreign = [ 'british', 'french', 'german', 'indian', 'iranian', 'malay', 'swedish', 'turkish', 'world-music']\n",
    "easy_listening = ['chill', 'classical', 'gospel', 'new-age', 'piano', 'romance', 'sad', 'sleep', 'study', 'comedy']\n",
    "super_genres = {'entertainment':entertainment,\n",
    "                'electronic':electronic,\n",
    "                'rock':rock,\n",
    "                'pop':pop,\n",
    "                'folk':folk,\n",
    "                'latin':latin,\n",
    "                'foreign':foreign,\n",
    "                'easy_listening':easy_listening}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_supergenre(genre_list, super_genre):\n",
    "    for i in range(0, genre_list.size):\n",
    "        for sg, glist in super_genre.items():\n",
    "            if genre_list.iloc[i] in glist:\n",
    "                genre_list.iloc[i] = sg\n",
    "    return genre_list\n",
    "\n",
    "ytrain_sup = map_to_supergenre(ytrain, super_genres)\n",
    "ytest_sup = map_to_supergenre(ytest, super_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## By cluster\n",
    "from sklearn.cluster import KMeans\n",
    "kmeans_per_k = [KMeans(n_clusters=k, n_init='auto', random_state=42).fit(x)\n",
    "                for k in range(2, 15)]\n",
    "inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(np.arange(2,15),inertias,marker=\"o\")\n",
    "plt.xlabel('Number of Clusters, K')\n",
    "plt.ylabel('WCSS')\n",
    "# 8 is a reasonable number of from the plot, and to make the best comparison with the chosen super-genre, we'll keep that\n",
    "xtrain_clust, xtest_clust, ytrain_clust, ytest_clust = train_test_split(x, kmeans_per_k[6].labels_, random_state=307, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are, however, some very uneven clusters, anomolous tracks.\n",
    "np.unique(kmeans_per_k[6].labels_, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models with Super Genre vs Natural Clusterings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_rf2 = RandomForestClassifier(n_estimators=500, random_state=7567)\n",
    "genre_rf2.fit(xtrain, ytrain_sup)\n",
    "yhat2 = genre_rf2.predict(xtest)\n",
    "c2 =  confusion_matrix(ytest_sup, yhat2)\n",
    "print(accuracy_score(ytest_sup, yhat2))\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.heatmap(c2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_rf3 = RandomForestClassifier(n_estimators=500, random_state=7567)\n",
    "genre_rf3.fit(xtrain, ytrain_clust)\n",
    "yhat3 = genre_rf3.predict(xtest)\n",
    "c3 =  confusion_matrix(ytest_clust, yhat3)\n",
    "print(accuracy_score(ytest_clust, yhat3))\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.heatmap(c3, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NAIVE BAYES\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB().fit(xtrain, ytrain)\n",
    "yhat_nb = nb.predict(xtest)\n",
    "cnb =  confusion_matrix(ytest_sup, yhat_nb)\n",
    "print(accuracy_score(ytest_sup, yhat_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clust = GaussianNB().fit(xtrain, ytrain_clust)\n",
    "yhat_nb_clust = nb_clust.predict(xtest)\n",
    "cnb_clust =  confusion_matrix(ytest_sup, yhat_nb)\n",
    "print(accuracy_score(ytest_clust, yhat_nb_clust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-class Method: Nearest Centroid\n",
    "This method attempts to perform like KNN without the high cost of prediction, namely by computing centroids of the groups. It turned out to be quite abysmal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = NearestCentroid().fit(xtrain, ytrain_sup)\n",
    "yhat_nc = nc.predict(xtest)\n",
    "c_nc =  confusion_matrix(ytest_sup, yhat_nc)\n",
    "print(accuracy_score(ytest_sup, yhat_nc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nc = NearestCentroid().fit(xtrain, ytrain_clust)\n",
    "yhat_nc_clust = nc.predict(xtest)\n",
    "c_nc_clust =  confusion_matrix(ytest_clust, yhat_nc_clust)\n",
    "print(accuracy_score(ytest_clust, yhat_nc_clust))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "# Dimension reduction was attempted using UMAP, however for computational constraints 5 neighbors were used.\n",
    "# I played with this for a very long time, and it never got any better.\n",
    "umap = UMAP(n_neighbors=5)\n",
    "um_5 = umap.fit_transform(x)\n",
    "labels = kmeans_per_k[6].labels_.astype(int)\n",
    "plt.scatter(um_5[:,0],um_5[:,1], c=labels)\n",
    "plt.xlabel('Dim 1')\n",
    "plt.ylabel('Dim 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations and Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = ['popularity', 'duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "xvis = pd.DataFrame(MinMaxScaler().fit_transform(xtrain.loc[:,num_vars]))\n",
    "xvis.columns = num_vars\n",
    "xvis['genre'] = ytrain_sup\n",
    "xvis['cluster'] = ytrain_clust\n",
    "xvis = xvis.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = ['entertainment', 'latin', 'folk', 'electronic', 'foreign',\n",
    "       'easy_listening', 'pop', 'rock']\n",
    "summaries_gen = {}\n",
    "for g in gen:\n",
    "    summaries_gen[g] = xvis.loc[xvis['genre'] == g,num_vars].mean()\n",
    "\n",
    "summaries_clust = {}\n",
    "for cl in range(8):\n",
    "    summaries_clust[cl] = xvis.loc[xvis['cluster'] == cl,num_vars].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g in gen:\n",
    "    temp = pd.DataFrame(summaries_gen[g])\n",
    "    temp.plot.bar(title=f'Super Genre \"{g}\" Attributes', legend=False)\n",
    "    plt.savefig(f'figures/attributes/genre_{g}.png', bbox_inches = \"tight\")\n",
    "\n",
    "for i in range(8):\n",
    "    temp = pd.DataFrame(summaries_clust[i])\n",
    "    temp.plot.bar(title=f'Cluster \"{i}\" Attributes', legend=False)\n",
    "    plt.savefig(f'figures/attributes/cluster_{i}.png', bbox_inches = \"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stat_486",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
